---
title: "Address Parsing in `R`"
author: "Christopher Prener, Ph.D."
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

`postmastr` is designed to be an *opinionated* toolkit for parsing street addresses using `R`. It was originally created to standardize addresses prior to geocoding the, in an effor to increase the geocoder's ability to correctly match a given address with the appropriate coordinates.

## Motivation
Street addresses can be notoriously difficult to work with. In the United States, the U.S. Postal Service has [standards for their composition](https://pe.usps.com/text/pub28/welcome.htm). There is so much variety, however, that anticipating all of the possible permutations of addresses is a significant task. When the inaccuracy of human data entry is added, the challenge of parsing addresses becomes monumental. The goal of `postmastr` is to provide a uniform workflow for parsing street address data that allows for sufficient flexibility. 

This flexibility is provided in two ways. First, we utilize "dictionaries" for a number of the key functions that allow users to provide vectors of data to base parsing on. This enables `postmastr` to parse potential misspellings and colloquial terms that are hard (or impossible) to predict. Second, not all aspects of the workflow are mandatory - if street address data do not contain postal codes, states, or cities, for example, those functions can be skipped. 

## A Grammar of Street Addresses

## Creating Dictionaries
### State Dictionaries
`postmastr` comes with a built-in dictionary of states and their abbreviations that can be expanded and filterd using `pm_dictionary()` and `pm_append()`. On its own, `pm_dictionary()` will return that built-in dictionary:

```r
> pm_dictionary(locale = "us", type = "state")
# A tibble: 124 x 2
   state.output state.input                                     
   <chr>        <chr>                                           
 1 AA           Armed Forces Americas                           
 2 AA           AA                                              
 3 AE           Armed Forces Europe, the Middle East, and Canada
 4 AE           AE                                              
 5 AK           AK                                              
 6 AK           Alaska                                          
 7 AL           AL                                              
 8 AL           Alabama                                         
 9 AP           Armed Forces Pacific                            
10 AP           AP                                              
# … with 114 more rows
```

If only a subset of states are included in your data, you can improve `postmastr`'s performance by limiting your state dictionary's contents. The `filter` argument can accept scalar or vector inputs of two-letter state abbreviations. For instance, we could construction a state dictionary that contains only the states along the Gulf of Mexico:

```r
> pm_dictionary(locale = "us", type = "state", filter = c("AL", "FL", "LA", "MS", "TX"))
# A tibble: 10 x 2
   state.output state.input
   <chr>        <chr>      
 1 AL           AL         
 2 AL           Alabama    
 3 FL           FL         
 4 FL           Florida    
 5 LA           LA         
 6 LA           Louisiana  
 7 MS           MS         
 8 MS           Mississippi
 9 TX           TX         
10 TX           Texas   
```

The state dictionary can also be expanded. For instance, there are several common abbreviations for Mississippi - "Miss" and "MISS". We can create an appendix with `pm_append()`:

```r
> miss <- pm_append(locale = "us", type = "state", input = c("Miss", "MISS"), output = c("MS", "MS"))
```

Once this has been created, we can combine it with the default state dictionary to create our custom dictionary output:

```r
> pm_dictionary(locale = "us", type = "state", append = miss, filter = c("AL", "FL", "LA", "MS", "TX"))
# A tibble: 12 x 2
   state.output state.input
   <chr>        <chr>      
 1 AL           AL         
 2 AL           Alabama    
 3 FL           FL         
 4 FL           Florida    
 5 LA           LA         
 6 LA           Louisiana  
 7 MS           MS         
 8 MS           Mississippi
 9 MS           Miss       
10 MS           MISS       
11 TX           TX         
12 TX           Texas 
```

All of the different inputs for Mississippi will now return the same `MS` output.

## The postmastr Workflow
To illustrate the core components of the `postmastr` workflow, we'll use some data on sushi resturants in the St. Louis, Missouri region. These are "long" data - some resturants appear multiple times. Here is a quick preview of the data:

```r
> sushi1
# A tibble: 30 x 3
   name                            address                                           visit   
   <chr>                           <chr>                                             <chr>   
 1 BaiKu Sushi Lounge              3407 Olive St, St. Louis, Missouri 63103          3/20/18 
 2 Blue Ocean Restaurant           6335 Delmar Blvd, St. Louis, MO 63112             10/26/18
 3 Cafe Mochi                      3221 S Grand Boulevard, St. Louis, MO 63118       10/10/18
 4 Drunken Fish - Ballpark Village 601 Clark Ave #104, St. Louis, MO 63102-1719      4/28/18 
 5 Drunken Fish - Ballpark Village 601 Clark Ave Suite 104, St. Louis, MO 63102-1719 5/10/18 
 6 Drunken Fish - Ballpark Village 601 Clark Ave Suite 104, St. Louis, MO 63102-1719 8/7/18  
 7 Drunken Fish - Central West End 1 Maryland Plaza, St. Louis, MO 63108             12/2/18 
 8 I Love Mr Sushi                 9443 Olive Blvd, St. Louis, Missouri 63132        1/1/18  
 9 Kampai Sushi Bar                4949 W Pine Blvd, St. Louis, MO 63108             2/13/18 
10 Midtown Sushi & Ramen           3674 Forest Park Ave, St. Louis, MO 63108         3/4/18  
# … with 20 more rows
```

Some problems should already be apparent. For instance, Cafe Mouchi uses the full word for "Boulevard" while the entry for Blue Ocean uses the proper abbreviation "Blvd". For Drunken Fish, the suite number is listed both using the pound sign ("#") as well as with the word "Suite". Finally, some of the entries including for BaiKu and I Love Mr Sushi use the full name for "Missouri" while the rest use the proper two-letter abbreviation "MO". Finally, the Drunk Fish - Ballpark Village uses the "zip+4" format as opposed to the remainder of the addresses visible, which contain only the five digit zip-code.

Some of the other entries have additional issues. For example, Sushi Koi has its address fully capitalized:

```r
> sushi1$address[[22]]
[1] "4 N EUCLID AVE, SAINT LOUIS, MO 63108"
```

Similarly, Wasabi Sushi Bar has its address fully capitalized, but the prefix direction "SOUTH" appears as a word rather than the proper "S":

```r
> sushi1$address[[30]]
[1] "16 SOUTH CENTRAL AVE, CLAYTON, MISSOURI 63105"
```

This vignette will walk through the process of addressing these issues.

### Prep
There are two initial prepretory steps that *must* be taken with these data. First, we want to ensure that they have a unique identification number for each row (to preserve the original sort order; `pm.id`) as well as a unique identification number for each *unique* street address string (`pm.uid`). These can both be applied using `pm.identify()`:

```r
> sushi1 <- pm_identify(sushi1, var = "address")
> sushi1
# A tibble: 30 x 5
   pm.id pm.uid name                            address                                           visit   
   <int>  <int> <chr>                           <chr>                                             <chr>   
 1     1      1 BaiKu Sushi Lounge              3407 Olive St, St. Louis, Missouri 63103          3/20/18 
 2     2      2 Blue Ocean Restaurant           6335 Delmar Blvd, St. Louis, MO 63112             10/26/18
 3     3      3 Cafe Mochi                      3221 S Grand Boulevard, St. Louis, MO 63118       10/10/18
 4     4      4 Drunken Fish - Ballpark Village 601 Clark Ave #104, St. Louis, MO 63102-1719      4/28/18 
 5     5      5 Drunken Fish - Ballpark Village 601 Clark Ave Suite 104, St. Louis, MO 63102-1719 5/10/18 
 6     6      5 Drunken Fish - Ballpark Village 601 Clark Ave Suite 104, St. Louis, MO 63102-1719 8/7/18  
 7     7      6 Drunken Fish - Central West End 1 Maryland Plaza, St. Louis, MO 63108             12/2/18 
 8     8      7 I Love Mr Sushi                 9443 Olive Blvd, St. Louis, Missouri 63132        1/1/18  
 9     9      8 Kampai Sushi Bar                4949 W Pine Blvd, St. Louis, MO 63108             2/13/18 
10    10      9 Midtown Sushi & Ramen           3674 Forest Park Ave, St. Louis, MO 63108         3/4/18  
# … with 20 more rows
```

Notice that the Drunken Fish has three different unique identifers applied for `pm.uid` - two for the Ballpark Village location based on how the suite number is indicated and one for the Central West End location. Since address data are often numerous, `postmastr` is designed to operate on unique street address strings rather than the full original data set to imrpove efficiency. We'll create our minimal `postmastr` object using `pm.prep()`:

```r
> sushi1_min <- pm_prep(sushi1, var = "address")
> sushi1_min
# A tibble: 24 x 2
   pm.uid pm.address                                     
    <int> <chr>                                          
 1      1 3407 Olive St St. Louis Missouri 63103         
 2      2 6335 Delmar Blvd St. Louis MO 63112            
 3      3 3221 S Grand Boulevard St. Louis MO 63118      
 4      4 601 Clark Ave #104 St. Louis MO 63102-1719     
 5      5 601 Clark Ave Suite 104 St. Louis MO 63102-1719
 6      6 1 Maryland Plaza St. Louis MO 63108            
 7      7 9443 Olive Blvd St. Louis Missouri 63132       
 8      8 4949 W Pine Blvd St. Louis MO 63108            
 9      9 3674 Forest Park Ave St. Louis MO 63108        
10     10 1013 Washington Avenue St. Louis MO 63101      
# … with 14 more rows
```

Notice that all extraneous information has been removed, and that there are now only 24 rows instead of the original 30.

### Postal Codes
All of the major grammatical elements of addresses have corresponding `has` and `parse` functions. The `has` functions return either a logical scalar if that grammatical element is found anywhere in the `postmastr` object *or*, with the `scalar = FALSE` argument, a logical vector identifying specific observations that contain that grammatical element.

For postal codes ("zip-codes" in the United States), the `has` function is `pm_has_postal()`. With the `sushi1_min` data, it will return `TRUE` because postal codes are present in the data:

```r
> pm_has_postal(sushi1_min)
[1] TRUE
```

We can see which observations have postal codes using the `scalar = FALSE` argument. This is particularly useful for more complex data situations where postal codes are misformatted and deeper cleaning before parsing is necessary. In this case, every observation has a valid postal code and so `pm.hasZip` contains all `TRUE` values:

```r
> pm_has_postal(sushi1_min, scalar = FALSE)
# A tibble: 24 x 3
   pm.uid pm.address                                      pm.hasZip
    <int> <chr>                                           <lgl>    
 1      1 3407 Olive St St. Louis Missouri 63103          TRUE     
 2      2 6335 Delmar Blvd St. Louis MO 63112             TRUE     
 3      3 3221 S Grand Boulevard St. Louis MO 63118       TRUE     
 4      4 601 Clark Ave #104 St. Louis MO 63102-1719      TRUE     
 5      5 601 Clark Ave Suite 104 St. Louis MO 63102-1719 TRUE     
 6      6 1 Maryland Plaza St. Louis MO 63108             TRUE     
 7      7 9443 Olive Blvd St. Louis Missouri 63132        TRUE     
 8      8 4949 W Pine Blvd St. Louis MO 63108             TRUE     
 9      9 3674 Forest Park Ave St. Louis MO 63108         TRUE     
10     10 1013 Washington Avenue St. Louis MO 63101       TRUE     
# … with 14 more rows
```

In a typical scenario, `pm_has_postal()` with the `scalar = FALSE` argument should be sufficent to prompt you to parse those postal codes. If `pm_parse_postal()` detects the presence of carrier routes (the four-digit additions to the typical five-digit zip-codes), it will parse those as well so that two postal code columns (`pm.zip` and `pm.zip4`) are returned:

```r
> sushi1_min <- pm_parse_postal(sushi1_min)
> sushi1_min
# A tibble: 24 x 4
   pm.uid pm.address                           pm.zip pm.zip4
    <int> <chr>                                <chr>  <chr>  
 1      1 3407 Olive St St. Louis Missouri     63103  NA     
 2      2 6335 Delmar Blvd St. Louis MO        63112  NA     
 3      3 3221 S Grand Boulevard St. Louis MO  63118  NA     
 4      4 601 Clark Ave #104 St. Louis MO      63102  1719   
 5      5 601 Clark Ave Suite 104 St. Louis MO 63102  1719   
 6      6 1 Maryland Plaza St. Louis MO        63108  NA     
 7      7 9443 Olive Blvd St. Louis Missouri   63132  NA     
 8      8 4949 W Pine Blvd St. Louis MO        63108  NA     
 9      9 3674 Forest Park Ave St. Louis MO    63108  NA     
10     10 1013 Washington Avenue St. Louis MO  63101  NA     
# … with 14 more rows
```

Had no carrier routes been present, these data would have been returned with only the `pm.zip` column. Note that `pm_parse_postal()` also updates the `pm.address` column and removes any postal codes that have been identified. This facilitates additional parsing in subsequent steps.

### States
To parse the cities out of `pm.address`, we'll start by creating a state-level dictionary object that contains only references to Missouri since we don't have data outside of that state:

```r
> moDict <- pm_dictionary(locale = "us", type = "state", filter = "MO")
> moDict
# A tibble: 4 x 2
  state.output state.input
  <chr>        <chr>      
1 MO           MO         
2 MO           Missouri   
3 MO           MISSOURI   
4 MO           missouri
```

With our dictionary created in the object `moDict`, we can use that to test whether state names or abbreviations are found at the end of our address string with `pm_has_state()`:

```r
> pm_has_state(sushi1_min, dictionary = moDict)
[1] TRUE
```

We could also explore these matches further to make sure that misspellings did not prevent `pm_has_state()` from identifying states by using the `scalar = FALSE` argument. We'll skip this step for now and attempt to parse the data using `pm_parse_state()`:

```r
> sushi1_min <- pm_parse_state(sushi1_min, dictionary = moDict)
> sushi1_min
# A tibble: 24 x 5
   pm.uid pm.address                        pm.state pm.zip pm.zip4
    <int> <chr>                             <chr>    <chr>  <chr>  
 1      1 3407 Olive St St. Louis           MO       63103  NA     
 2      2 6335 Delmar Blvd St. Louis        MO       63112  NA     
 3      3 3221 S Grand Boulevard St. Louis  MO       63118  NA     
 4      4 601 Clark Ave #104 St. Louis      MO       63102  1719   
 5      5 601 Clark Ave Suite 104 St. Louis MO       63102  1719   
 6      6 1 Maryland Plaza St. Louis        MO       63108  NA     
 7      7 9443 Olive Blvd St. Louis         MO       63132  NA     
 8      8 4949 W Pine Blvd St. Louis        MO       63108  NA     
 9      9 3674 Forest Park Ave St. Louis    MO       63108  NA     
10     10 1013 Washington Avenue St. Louis  MO       63101  NA     
# … with 14 more rows
```

If we inspect this object, we'll see that `pm.state` contains the state abbreviation for Missouri in all cases. As with postal codes, the city names have been removed from `pm.address` to facilitate the next phase in parsing.

### Cities

### Units

### House Numbers

### Street Prefix and Suffix Data

### Street Names

### Putting It All Back Together

## Getting Help
* If you are new to `R` itself, welcome! Hadley Wickham's [*R for Data Science*](http://r4ds.had.co.nz) is an excellent way to get started with data manipulation in the tidyverse, which `stlcsb` is designed to integrate seamlessly with.
* If you have questions about using `postmastr`, you are encouraged to use the [RStudio Community forums](https://community.rstudio.com). Please create a [`reprex`](http://reprex.tidyverse.org/) before posting. Feel free to tag Chris (`@chris.prener`) in any posts about `postmastr`.
* If you think you've found a bug, please create a [`reprex`](http://reprex.tidyverse.org/) and then open an issue on [GitHub](https://github.com/slu-openGIS/stlcsb/issues/new/choose).
